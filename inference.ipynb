{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbbbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "from multiprocessing import Process\n",
    "\n",
    "join = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ea137",
   "metadata": {},
   "source": [
    "# Preparing as nnunetv2 format\n",
    "Before proceeding, ensure that your dataset is properly formatted and ready for integration with the nnU-Net framework.\n",
    "It is assumed that all preprocessing steps have already been completed and that the data is conformed to the required structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../splits/CNP_patients.txt\", \"r\") as f:\n",
    "    dwi_eddy_paths = [line.strip() for line in f]\n",
    "patient_ids = sorted(dwi_eddy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e92b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/hdd/CNP_dataset\"\n",
    "\n",
    "folder_to_predict = join(root_path, \"to_pred_T+F+S+Max\")\n",
    "os.makedirs(folder_to_predict, exist_ok=True)\n",
    "for patient_id in tqdm(\n",
    "    patient_ids, desc=\"Copying files to predict\", total=len(patient_ids)\n",
    "):\n",
    "    fa_path = join(\n",
    "        root_path, \"data\", patient_id, \"DATA\", \"images\", \"FA_ras_MNI_conform.nii.gz\"\n",
    "    )\n",
    "    if not os.path.exists(fa_path):\n",
    "        print(f\"File {fa_path} does not exist. Skipping...\")\n",
    "        continue\n",
    "    trace_path = join(\n",
    "        root_path,\n",
    "        \"data\",\n",
    "        patient_id,\n",
    "        \"DATA\",\n",
    "        \"images\",\n",
    "        \"trace_from_eigs_ras_MNI_conform.nii.gz\",\n",
    "    )\n",
    "    sphericity_path = join(\n",
    "        root_path,\n",
    "        \"data\",\n",
    "        patient_id,\n",
    "        \"DATA\",\n",
    "        \"images\",\n",
    "        \"sphericity_ras_MNI_conform.nii.gz\",\n",
    "    )\n",
    "    max_eigenvalue_path = join(\n",
    "        root_path, \"data\", patient_id, \"DATA\", \"images\", \"maxEig_ras_MNI_conform.nii.gz\"\n",
    "    )\n",
    "    # Copy the files from the results directory to the new folder\n",
    "    shutil.copy(fa_path, join(folder_to_predict, f\"{patient_id}_0000.nii.gz\"))\n",
    "    shutil.copy(trace_path, join(folder_to_predict, f\"{patient_id}_0001.nii.gz\"))\n",
    "    shutil.copy(sphericity_path, join(folder_to_predict, f\"{patient_id}_0002.nii.gz\"))\n",
    "    shutil.copy(\n",
    "        max_eigenvalue_path, join(folder_to_predict, f\"{patient_id}_0003.nii.gz\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a4ddd",
   "metadata": {},
   "source": [
    "# First stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c858b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = (\n",
    "    \"/hdd/CNP_dataset/to_pred_T+F+S+Max\"  # \"/hdd/HPC_retest_preprocess/to_predict/\"\n",
    ")\n",
    "output_path = \"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR/seven_class/\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "model_path = \"/hdd/nnunet_dataset/Parcel_final/SwinUNETR/Dataset630_dMRI_FA_trace_sphericity_maxEig_V3_7_classes/SwinUnetrBratsTrainer__nnUNetPlans__3d_fullres/\"\n",
    "seven_class_command = f\"nnUNetv2_predict_from_modelfolder -i {input_path} -o {output_path} -m {model_path} -f 0 --disable_progress_bar\"\n",
    "subprocess.run(seven_class_command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72b287",
   "metadata": {},
   "source": [
    "# Moving the data in a place to be ready for the second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27166d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new prediction folder for the subsequent steps\n",
    "new_prediction_path = (\n",
    "    \"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR/to_predict_with_seven_class\"\n",
    ")\n",
    "os.makedirs(new_prediction_path, exist_ok=True)\n",
    "for patient_id in tqdm(\n",
    "    patient_ids, desc=\"Copying files to predict\", total=len(patient_ids)\n",
    "):\n",
    "    fa_path = join(\n",
    "        root_path, \"data\", patient_id, \"DATA\", \"images\", \"FA_ras_MNI_conform.nii.gz\"\n",
    "    )\n",
    "    trace_path = join(\n",
    "        root_path,\n",
    "        \"data\",\n",
    "        patient_id,\n",
    "        \"DATA\",\n",
    "        \"images\",\n",
    "        \"trace_from_eigs_ras_MNI_conform.nii.gz\",\n",
    "    )\n",
    "    sphericity_path = join(\n",
    "        root_path,\n",
    "        \"data\",\n",
    "        patient_id,\n",
    "        \"DATA\",\n",
    "        \"images\",\n",
    "        \"sphericity_ras_MNI_conform.nii.gz\",\n",
    "    )\n",
    "    max_eigenvalue_path = join(\n",
    "        root_path, \"data\", patient_id, \"DATA\", \"images\", \"maxEig_ras_MNI_conform.nii.gz\"\n",
    "    )\n",
    "    seven_class_path = join(output_path, f\"{patient_id}.nii.gz\")\n",
    "    # Copy the files from the results directory to the new folder\n",
    "    shutil.copy(fa_path, join(new_prediction_path, f\"{patient_id}_0000.nii.gz\"))\n",
    "    shutil.copy(trace_path, join(new_prediction_path, f\"{patient_id}_0001.nii.gz\"))\n",
    "    shutil.copy(sphericity_path, join(new_prediction_path, f\"{patient_id}_0002.nii.gz\"))\n",
    "    shutil.copy(\n",
    "        max_eigenvalue_path, join(new_prediction_path, f\"{patient_id}_0003.nii.gz\")\n",
    "    )\n",
    "    shutil.copy(\n",
    "        seven_class_path, join(new_prediction_path, f\"{patient_id}_0004.nii.gz\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966e882",
   "metadata": {},
   "source": [
    "# Now if you have enough RAM and VRAM you can run the second stage by multiprocessing if not you can use single processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73423f0c",
   "metadata": {},
   "source": [
    "## Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(command):\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "\n",
    "input_path = new_prediction_path\n",
    "output_paths = [\"center\", \"left\", \"right\", \"right_small\", \"left_small\"]\n",
    "model_paths = [\n",
    "    \"Dataset636_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_center_classes\",\n",
    "    \"Dataset637_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_left_classes\",\n",
    "    \"Dataset639_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_right_classes\",\n",
    "    \"Dataset640_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_right_small_classes\",\n",
    "    \"Dataset638_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_left_small_classes\",\n",
    "]\n",
    "# output_paths=[\"center\",\"right_small\",\"left_small\"]\n",
    "# model_paths=[\"Dataset636_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_center_classes\",\n",
    "#              \"Dataset640_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_right_small_classes\",\"Dataset638_dMRI_MedNeXt_FA_trace_sphericity_maxEig_V3_left_small_classes\"]\n",
    "processes = []\n",
    "for output_path, model_path in zip(output_paths, model_paths):\n",
    "    output_path = join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_mednext\", output_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    model_path = join(\n",
    "        \"/hdd/nnunet_dataset/Parcel_final/MedNeXt\",\n",
    "        model_path,\n",
    "        \"MednextBratsTrainer__nnUNetResEncUNetMPlans__3d_fullres\",\n",
    "    )\n",
    "    command = f\"nnUNetv2_predict_from_modelfolder -i {input_path} -o {output_path} -m {model_path} -f 0 --c --disable_progress_bar\"\n",
    "    processes.append(Process(target=run_subprocess, args=(command,)))\n",
    "    processes[-1].start()\n",
    "for process in processes:\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036f9d3",
   "metadata": {},
   "source": [
    "## Single Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(command):\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "\n",
    "input_path = new_prediction_path\n",
    "output_paths = [\"center\", \"left\", \"right\", \"right_small\", \"left_small\"]\n",
    "model_paths = [\n",
    "    \"Dataset641_dMRI_SwinUNETR_FA_trace_sphericity_maxEig_V3_center_classes\",\n",
    "    \"Dataset642_dMRI_SwinUNETR_FA_trace_sphericity_maxEig_V3_left_classes\",\n",
    "    \"Dataset644_dMRI_SwinUNETR_FA_trace_sphericity_maxEig_V3_right_classes\",\n",
    "    \"Dataset645_dMRI_SwinUNETR_FA_trace_sphericity_maxEig_V3_right_small_classes\",\n",
    "    \"Dataset643_dMRI_SwinUNETR_FA_trace_sphericity_maxEig_V3_left_small_classes\",\n",
    "]\n",
    "\n",
    "# processes = []\n",
    "for output_path, model_path in zip(output_paths, model_paths):\n",
    "    output_path = join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", output_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    model_path = join(\n",
    "        \"/hdd/nnunet_dataset/Parcel_final/SwinUNETR\",\n",
    "        model_path,\n",
    "        \"SwinUnetrBratsTrainer__nnUNetPlans__3d_fullres\",\n",
    "    )\n",
    "    command = f\"nnUNetv2_predict_from_modelfolder -i {input_path} -o {output_path} -m {model_path} -f 0 --c --disable_progress_bar\"\n",
    "    print(output_path)\n",
    "    run_subprocess(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656d539",
   "metadata": {},
   "source": [
    "# Managing the predicted folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528be07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder that should be used for the prediction\n",
    "seven_class_paths = sorted(\n",
    "    glob(join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", \"seven_class\", \"*.nii.gz\"))\n",
    ")\n",
    "print(f\"Number of files in seven_class: {len(seven_class_paths)}\")\n",
    "center_paths = sorted(\n",
    "    glob(join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", \"center\", \"*.nii.gz\"))\n",
    ")\n",
    "print(f\"Number of files in center: {len(center_paths)}\")\n",
    "left_paths = sorted(\n",
    "    glob(join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", \"left\", \"*.nii.gz\"))\n",
    ")\n",
    "print(f\"Number of files in left: {len(left_paths)}\")\n",
    "right_paths = sorted(\n",
    "    glob(join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", \"right\", \"*.nii.gz\"))\n",
    ")\n",
    "print(f\"Number of files in right: {len(right_paths)}\")\n",
    "right_small_paths = sorted(\n",
    "    glob(join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", \"right_small\", \"*.nii.gz\"))\n",
    ")\n",
    "print(f\"Number of files in right_small: {len(right_small_paths)}\")\n",
    "left_small_paths = sorted(\n",
    "    glob(join(\"/hdd/tmp/DMRI_PRED/CNP_T+F+S+Max_SwinUNETR\", \"left_small\", \"*.nii.gz\"))\n",
    ")\n",
    "print(f\"Number of files in left_small: {len(left_small_paths)}\")\n",
    "zipped_objects = zip(\n",
    "    seven_class_paths,\n",
    "    center_paths,\n",
    "    left_paths,\n",
    "    right_paths,\n",
    "    right_small_paths,\n",
    "    left_small_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a7488",
   "metadata": {},
   "source": [
    "# Getting the mappings files ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e52325",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {}\n",
    "sets = set()\n",
    "mapping_root = \"/home/say26747/Desktop/git/DDParcel_Yousef/mappings\"\n",
    "for map in sorted(glob(join(mapping_root, \"*.json\"))):\n",
    "    with open(map, \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    mappings[os.path.basename(map).split(\".\")[0]] = mapping\n",
    "    for value in mapping.values():\n",
    "        sets.add(value)\n",
    "\n",
    "print(f\"Number of unique values in all mappings: {len(sets)}\")\n",
    "\n",
    "with open(\n",
    "    \"/home/say26747/Desktop/git/DDParcel_Yousef/Preprocess_HCP/wmparc_values_to_sequence.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    wmparc_values_to_sequence = json.load(f)\n",
    "\n",
    "sequence_to_wmparc = {int(v): int(k) for k, v in wmparc_values_to_sequence.items()}\n",
    "\n",
    "mapping_dict = {\n",
    "    \"seven_mapping\": mappings[\"seven_mapping\"],\n",
    "    \"center_mapping\": mappings[\"center_mapping\"],\n",
    "    \"left_mapping\": mappings[\"left_mapping\"],\n",
    "    \"right_mapping\": mappings[\"right_mapping\"],\n",
    "    \"right_small_mapping\": mappings[\"left_small_mapping\"],\n",
    "    \"left_small_mapping\": mappings[\"right_small_mapping\"],\n",
    "}\n",
    "\n",
    "results_dir = \"/hdd/CNP_dataset/predicted_SwinUNETR/\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d667b884",
   "metadata": {},
   "source": [
    "# Fusion and post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(\n",
    "    seven_path, center_path, left_path, right_path, left_small_path, right_small_path\n",
    "):\n",
    "    if os.path.exists(join(results_dir, os.path.basename(center_path))):\n",
    "        print(f\"File {os.path.basename(center_path)} already exists. Skipping...\")\n",
    "        return\n",
    "    seven_img = nib.load(seven_path)\n",
    "    center_img = nib.load(center_path)\n",
    "    left_img = nib.load(left_path)\n",
    "    right_img = nib.load(right_path)\n",
    "    left_small_img = nib.load(left_small_path)\n",
    "    right_small_img = nib.load(right_small_path)\n",
    "\n",
    "    seven_data = seven_img.get_fdata()\n",
    "    center_data = center_img.get_fdata()\n",
    "    left_data = left_img.get_fdata()\n",
    "    right_data = right_img.get_fdata()\n",
    "    left_small_data = left_small_img.get_fdata()\n",
    "    right_small_data = right_small_img.get_fdata()\n",
    "\n",
    "    # Create a new array to hold the combined data\n",
    "    combined_data = np.zeros(center_data.shape, dtype=np.int32)\n",
    "\n",
    "    # Function to map the labels and update the combined data\n",
    "    def process_data(data, mapping_name):\n",
    "        unique_labels = np.unique(data)\n",
    "        # sets = set()\n",
    "        for label in unique_labels:\n",
    "            label = int(label)\n",
    "            if str(label) in mapping_dict[mapping_name]:\n",
    "                value = wmparc_values_to_sequence[\n",
    "                    str(mapping_dict[mapping_name][str(label)])\n",
    "                ]\n",
    "                # sets.add(value)\n",
    "                combined_data[data == label] = value\n",
    "        # return sets\n",
    "\n",
    "    process_data(seven_data, \"seven_mapping\")\n",
    "    process_data(center_data, \"center_mapping\")\n",
    "    process_data(left_data, \"left_mapping\")\n",
    "    process_data(right_data, \"right_mapping\")\n",
    "    process_data(left_small_data, \"left_small_mapping\")\n",
    "    process_data(right_small_data, \"right_small_mapping\")\n",
    "\n",
    "    # transform the prediction back to wmparc values\n",
    "    mapped = np.empty_like(combined_data, dtype=np.int32)\n",
    "    for k, v in sequence_to_wmparc.items():\n",
    "        mapped[combined_data == k] = v\n",
    "\n",
    "    # Create a new NIfTI image with the combined data\n",
    "    combined_img = nib.Nifti1Image(\n",
    "        mapped, center_img.affine, header=center_img.header.set_data_dtype(np.int32)\n",
    "    )\n",
    "    output_filename = join(results_dir, os.path.basename(center_path))\n",
    "\n",
    "    nib.save(combined_img, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a61d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_and_save)(\n",
    "        seven_path,\n",
    "        center_path,\n",
    "        left_path,\n",
    "        right_path,\n",
    "        left_small_path,\n",
    "        right_small_path,\n",
    "    )\n",
    "    for seven_path, center_path, left_path, right_path, left_small_path, right_small_path in tqdm(\n",
    "        zipped_objects, desc=\"Processing files\", total=len(seven_class_paths)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36ec1f",
   "metadata": {},
   "source": [
    "# Moving the data to their original state (reverse transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResampleScalarVectorDWIVolume = \"/home/say26747/Downloads/Slicer-5.2.2-linux-amd64/Slicer --launch /home/say26747/Downloads/Slicer-5.2.2-linux-amd64/lib/Slicer-5.2/cli-modules/ResampleScalarVectorDWIVolume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformed_pred_path = \"/hdd/CNP_dataset/predicted_SwinUNETR_T+F\"\n",
    "normal_pred_path = \"/hdd/CNP_dataset/predicted_SwinUNETR_T+F_normal\"\n",
    "os.makedirs(normal_pred_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4200fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_MNI_to_RAS(patient_id):\n",
    "    conformed_pred = join(conformed_pred_path, f\"{patient_id}.nii.gz\")\n",
    "    normal_pred = join(normal_pred_path, f\"{patient_id}.nii.gz\")\n",
    "    ResampleScalarVectorDWIVolume_command = ResampleScalarVectorDWIVolume.split() + [\n",
    "        \"--interpolation\",\n",
    "        \"nn\",\n",
    "        \"--Reference\",\n",
    "        join(\n",
    "            \"/hdd/CNP_dataset/data/\",\n",
    "            patient_id,\n",
    "            \"DATA\",\n",
    "            \"labels\",\n",
    "            \"brain_mask_ras.nii.gz\",\n",
    "        ),\n",
    "        \"--transformationFile\",\n",
    "        join(\n",
    "            \"/hdd/CNP_dataset/data/\",\n",
    "            patient_id,\n",
    "            \"DATA\",\n",
    "            \"transformations\",\n",
    "            \"b0_to_MNI_Brain_Inverse.h5\",\n",
    "        ),\n",
    "        conformed_pred,\n",
    "        normal_pred,\n",
    "    ]\n",
    "    subprocess.run(ResampleScalarVectorDWIVolume_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2865e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(worker_MNI_to_RAS)(patient_id)\n",
    "    for patient_id in tqdm(patient_ids, desc=\"Processing files\", total=len(patient_ids))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
