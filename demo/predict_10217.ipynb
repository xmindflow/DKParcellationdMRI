{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b504231",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934cbe29",
   "metadata": {},
   "source": [
    "In this section, we perform inference on a subject from the CNP cohort.\n",
    "All preprocessing steps have already been completed, and the corresponding transformations have been saved along with the diffusion-derived parameters (FA, Trace, Sphericity, and Maximum Eigenvalue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip sub-10217.zip -d ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af87599",
   "metadata": {},
   "source": [
    "## Libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5850fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "from multiprocessing import Process\n",
    "from copy import deepcopy\n",
    "\n",
    "join = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece05d9d",
   "metadata": {},
   "source": [
    "# Paths to model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d934b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on where you put the data and weights, change the paths here\n",
    "weight_path = \"/hdd/nnunet_dataset/Parcel_final/nnunet\"\n",
    "trainer_name = \"nnUNetTrainer__nnUNetPlans__3d_fullres\"\n",
    "\n",
    "# depending on the path of Slicer in your system, change the path here\n",
    "ResampleScalarVectorDWIVolume = \"/home/say26747/Downloads/Slicer-5.2.2-linux-amd64/Slicer --launch /home/say26747/Downloads/Slicer-5.2.2-linux-amd64/lib/Slicer-5.2/cli-modules/ResampleScalarVectorDWIVolume\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00d57f",
   "metadata": {},
   "source": [
    "# Making the data as the nnUNet needs it as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getcwd()\n",
    "folder_to_predict = join(root_path, \"tmp_to_pred_T+F+S+Max\")\n",
    "os.makedirs(folder_to_predict, exist_ok=True)\n",
    "patient_id = \"sub-10217\"\n",
    "fa_path = join(root_path, patient_id, \"images\", \"FA_ras_MNI_conform.nii.gz\")\n",
    "trace_path = join(\n",
    "    root_path, patient_id, \"images\", \"trace_from_eigs_ras_MNI_conform.nii.gz\"\n",
    ")\n",
    "sphericity_path = join(\n",
    "    root_path, patient_id, \"images\", \"sphericity_ras_MNI_conform.nii.gz\"\n",
    ")\n",
    "max_eigenvalue_path = join(\n",
    "    root_path, patient_id, \"images\", \"maxEig_ras_MNI_conform.nii.gz\"\n",
    ")\n",
    "# Copy the files from the results directory to the new folder\n",
    "shutil.copy(fa_path, join(folder_to_predict, f\"{patient_id}_0000.nii.gz\"))\n",
    "shutil.copy(trace_path, join(folder_to_predict, f\"{patient_id}_0001.nii.gz\"))\n",
    "shutil.copy(sphericity_path, join(folder_to_predict, f\"{patient_id}_0002.nii.gz\"))\n",
    "shutil.copy(max_eigenvalue_path, join(folder_to_predict, f\"{patient_id}_0003.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33059a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = folder_to_predict\n",
    "output_path = join(root_path, \"tmp_pred_7_classes\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "# the model path should the weights for the seven class prediction\n",
    "model_path = join(\n",
    "    weight_path,\n",
    "    \"Dataset630_dMRI_FA_trace_sphericity_maxEig_V3_7_classes\",\n",
    "    trainer_name,\n",
    ")\n",
    "seven_class_command = f\"nnUNetv2_predict_from_modelfolder -i {input_path} -o {output_path} -m {model_path} -f 0 --disable_progress_bar\"\n",
    "subprocess.run(seven_class_command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc33593",
   "metadata": {},
   "source": [
    "# moving the predicted 7 class with other diffusion derived parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_class_path = join(output_path, f\"{patient_id}.nii.gz\")\n",
    "shutil.copy(seven_class_path, join(folder_to_predict, f\"{patient_id}_0004.nii.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91841bf",
   "metadata": {},
   "source": [
    "# Predict the second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd811e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(command):\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "\n",
    "# check that teh output path and model path are correctly ordered for each of the 5 models\n",
    "output_paths = [\"center\", \"left\", \"right\", \"right_small\", \"left_small\"]\n",
    "model_paths = [\n",
    "    \"Dataset631_dMRI_nnUNet_FA_trace_sphericity_maxEig_V3_center_classes\",\n",
    "    \"Dataset632_dMRI_nnUNet_FA_trace_sphericity_maxEig_V3_left_classes\",\n",
    "    \"Dataset634_dMRI_nnUNet_FA_trace_sphericity_maxEig_V3_right_classes\",\n",
    "    \"Dataset635_dMRI_nnUNet_FA_trace_sphericity_maxEig_V3_right_small_classes\",\n",
    "    \"Dataset633_dMRI_nnUNet_FA_trace_sphericity_maxEig_V3_left_small_classes\",\n",
    "]\n",
    "\n",
    "for output_path, model_path in zip(output_paths, model_paths):\n",
    "    output_path = join(root_path, f\"tmp_{output_path}\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    model_path = join(\n",
    "        weight_path,\n",
    "        model_path,\n",
    "        trainer_name,\n",
    "    )\n",
    "    command = f\"nnUNetv2_predict_from_modelfolder -i {input_path} -o {output_path} -m {model_path} -f 0 --c --disable_progress_bar\"\n",
    "    print(output_path)\n",
    "    run_subprocess(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba983943",
   "metadata": {},
   "source": [
    "# Fusion and post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf010334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder that should be used for the prediction\n",
    "seven_class_paths = sorted(glob(join(root_path, \"tmp_pred_7_classes\", \"*.nii.gz\")))\n",
    "print(f\"Number of files in tmp_pred_7_classes: {len(seven_class_paths)}\")\n",
    "center_paths = sorted(glob(join(root_path, \"tmp_center\", \"*.nii.gz\")))\n",
    "print(f\"Number of files in center: {len(center_paths)}\")\n",
    "left_paths = sorted(glob(join(root_path, \"tmp_left\", \"*.nii.gz\")))\n",
    "print(f\"Number of files in left: {len(left_paths)}\")\n",
    "right_paths = sorted(glob(join(root_path, \"tmp_right\", \"*.nii.gz\")))\n",
    "print(f\"Number of files in right: {len(right_paths)}\")\n",
    "right_small_paths = sorted(glob(join(root_path, \"tmp_right_small\", \"*.nii.gz\")))\n",
    "print(f\"Number of files in right_small: {len(right_small_paths)}\")\n",
    "left_small_paths = sorted(glob(join(root_path, \"tmp_left_small\", \"*.nii.gz\")))\n",
    "print(f\"Number of files in left_small: {len(left_small_paths)}\")\n",
    "zipped_objects = zip(\n",
    "    seven_class_paths,\n",
    "    center_paths,\n",
    "    left_paths,\n",
    "    right_paths,\n",
    "    right_small_paths,\n",
    "    left_small_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe75637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in all mappings: 101\n"
     ]
    }
   ],
   "source": [
    "mappings = {}\n",
    "sets = set()\n",
    "mapping_root = join(root_path, \"..\", \"utils\", \"mappings\")\n",
    "for map in sorted(glob(join(mapping_root, \"*.json\"))):\n",
    "    with open(map, \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    mappings[os.path.basename(map).split(\".\")[0]] = mapping\n",
    "    for value in mapping.values():\n",
    "        sets.add(value)\n",
    "\n",
    "print(f\"Number of unique values in all mappings: {len(sets)}\")\n",
    "\n",
    "with open(\n",
    "    join(root_path, \"..\", \"utils\", \"wmparc_values_to_sequence.json\"),\n",
    "    \"r\",\n",
    ") as f:\n",
    "    wmparc_values_to_sequence = json.load(f)\n",
    "\n",
    "sequence_to_wmparc = {int(v): int(k) for k, v in wmparc_values_to_sequence.items()}\n",
    "\n",
    "mapping_dict = {\n",
    "    \"seven_mapping\": mappings[\"seven_mapping\"],\n",
    "    \"center_mapping\": mappings[\"center_mapping\"],\n",
    "    \"left_mapping\": mappings[\"left_mapping\"],\n",
    "    \"right_mapping\": mappings[\"right_mapping\"],\n",
    "    \"right_small_mapping\": mappings[\"left_small_mapping\"],\n",
    "    \"left_small_mapping\": mappings[\"right_small_mapping\"],\n",
    "}\n",
    "\n",
    "results_dir = join(root_path, \"tmp_prediction\")\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b800201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(\n",
    "    seven_path, center_path, left_path, right_path, left_small_path, right_small_path\n",
    "):\n",
    "    if os.path.exists(join(results_dir, os.path.basename(center_path))):\n",
    "        print(f\"File {os.path.basename(center_path)} already exists. Skipping...\")\n",
    "        return\n",
    "    seven_img = nib.load(seven_path)\n",
    "    center_img = nib.load(center_path)\n",
    "    left_img = nib.load(left_path)\n",
    "    right_img = nib.load(right_path)\n",
    "    left_small_img = nib.load(left_small_path)\n",
    "    right_small_img = nib.load(right_small_path)\n",
    "\n",
    "    seven_data = seven_img.get_fdata()\n",
    "    center_data = center_img.get_fdata()\n",
    "    left_data = left_img.get_fdata()\n",
    "    right_data = right_img.get_fdata()\n",
    "    left_small_data = left_small_img.get_fdata()\n",
    "    right_small_data = right_small_img.get_fdata()\n",
    "\n",
    "    # Create a new array to hold the combined data\n",
    "    combined_data = np.zeros(center_data.shape, dtype=np.int32)\n",
    "\n",
    "    # Function to map the labels and update the combined data\n",
    "    def process_data(data, mapping_name):\n",
    "        unique_labels = np.unique(data)\n",
    "        # sets = set()\n",
    "        for label in unique_labels:\n",
    "            label = int(label)\n",
    "            if str(label) in mapping_dict[mapping_name]:\n",
    "                value = wmparc_values_to_sequence[\n",
    "                    str(mapping_dict[mapping_name][str(label)])\n",
    "                ]\n",
    "                # sets.add(value)\n",
    "                combined_data[data == label] = value\n",
    "        # return sets\n",
    "\n",
    "    process_data(seven_data, \"seven_mapping\")\n",
    "    process_data(center_data, \"center_mapping\")\n",
    "    process_data(left_data, \"left_mapping\")\n",
    "    process_data(right_data, \"right_mapping\")\n",
    "    process_data(left_small_data, \"left_small_mapping\")\n",
    "    process_data(right_small_data, \"right_small_mapping\")\n",
    "\n",
    "    # transform the prediction back to wmparc values\n",
    "    mapped = np.empty_like(combined_data, dtype=np.int32)\n",
    "    for k, v in sequence_to_wmparc.items():\n",
    "        mapped[combined_data == k] = v\n",
    "\n",
    "    # Create a new NIfTI image with the combined data\n",
    "    combined_img = nib.Nifti1Image(\n",
    "        mapped, center_img.affine, header=center_img.header.set_data_dtype(np.int32)\n",
    "    )\n",
    "    output_filename = join(results_dir, os.path.basename(center_path))\n",
    "\n",
    "    nib.save(combined_img, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87498841",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_save(\n",
    "    seven_class_paths[0],\n",
    "    center_paths[0],\n",
    "    left_paths[0],\n",
    "    right_paths[0],\n",
    "    right_small_paths[0],\n",
    "    left_small_paths[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8550d",
   "metadata": {},
   "source": [
    "# Moving the data to their original state (reverse transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84983cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformed_pred_path = join(root_path, \"tmp_prediction\")\n",
    "normal_pred_path = root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805b9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_MNI_to_RAS(patient_id):\n",
    "    conformed_pred = join(conformed_pred_path, f\"{patient_id}.nii.gz\")\n",
    "    normal_pred = join(normal_pred_path, f\"{patient_id}.nii.gz\")\n",
    "    ResampleScalarVectorDWIVolume_command = ResampleScalarVectorDWIVolume.split() + [\n",
    "        \"--interpolation\",\n",
    "        \"nn\",\n",
    "        \"--Reference\",\n",
    "        join(\n",
    "            root_path,\n",
    "            patient_id,\n",
    "            \"labels\",\n",
    "            \"brain_mask_ras.nii.gz\",\n",
    "        ),\n",
    "        \"--transformationFile\",\n",
    "        join(\n",
    "            root_path,\n",
    "            patient_id,\n",
    "            \"transformations\",\n",
    "            \"b0_to_MNI_Brain_Inverse.h5\",\n",
    "        ),\n",
    "        conformed_pred,\n",
    "        normal_pred,\n",
    "    ]\n",
    "    subprocess.run(ResampleScalarVectorDWIVolume_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568df291",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_MNI_to_RAS(\"sub-10217\")\n",
    "shutil.move(\n",
    "    join(root_path, \"sub-10217.nii.gz\"), join(root_path, \"sub-10217-wmparc.nii.gz\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ada0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all the temporary folders\n",
    "folders_to_delete = glob(join(root_path, \"tmp*\"))\n",
    "for folder in folders_to_delete:\n",
    "    shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6188bb6",
   "metadata": {},
   "source": [
    "# Use freeview to visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!freeview -v sub-10217/images/FA_ras.nii.gz -v sub-10217-wmparc.nii.gz:colormap=lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cf01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
